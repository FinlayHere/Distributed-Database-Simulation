{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Databases and Big Data\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "- You will be using Python 3.\n",
    "- Read the assignment instruction carefully and implement the algorithms in this workbook. \n",
    "- You can use the datasets fireData and climateData (provided below) if you are aiming for Credit Task.\n",
    "- For Distinction and High Distinction tasks, you are required to read the files FireData.csv and ClimateData.CSV provided with the assignment programatically and prepare the data in the correct format so that it can be used in your algorithm. \n",
    "- You can introduce new cells as necessary.\n",
    "\n",
    "**Your details**\n",
    "- Name: FANCHAO KONG \n",
    "\n",
    "\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas to read file\n",
    "import csv\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file data to memeory\n",
    "# fireData\n",
    "fireData = []\n",
    "with open('FireData.csv') as firePath:\n",
    "    reader = csv.reader(firePath)\n",
    "    for row in reader:\n",
    "        fireData.append(row)\n",
    "#climateData\n",
    "climateData = []\n",
    "with open('ClimateData.csv') as climatePath:\n",
    "    reader = csv.reader(climatePath)\n",
    "    for row in reader:\n",
    "        climateData.append(row)\n",
    "del fireData[0]\n",
    "del climateData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['948700',\n",
       "  '2016-12-31',\n",
       "  '19',\n",
       "  '56.8',\n",
       "  '7.9',\n",
       "  '11.1',\n",
       "  '   72.0*',\n",
       "  '  61.9*',\n",
       "  ' 0.00I']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climateData[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-37.966',\n",
       "  '145.051',\n",
       "  '341.8',\n",
       "  '2017-12-27T04:16:51',\n",
       "  '26.7',\n",
       "  '78',\n",
       "  '2017-12-27',\n",
       "  '68']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireData[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 ：Parallel Search\n",
    "\n",
    "### 1. Write an algorithm to search climate data for the records on  15th December 2017 . Justify your choice of the data partition technique and search technique you have used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Assume that we have 3 processors, as a result we can divde the data to 3 parts by using two time nodes. \n",
    "For divde equally, the time node shuold be the date of 10 and 20. If date less than 10 put it to first processor, else \n",
    "if it greater than 10 and less 20, put it to second processor, else put it to the last one.\n",
    "'''\n",
    "def task1_1_whichProcessor(date):\n",
    "\n",
    "    if int(date[-2:]) <= 10:\n",
    "        return 0\n",
    "    else:\n",
    "        if int(date[-2:]) <= 20:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "        \n",
    "'''\n",
    "This is the algorithm how we partioning data, for each record in the target table, we take the date value and compare\n",
    "with the time node. This function will back a value to piont the exactly which processor\n",
    "'''\n",
    "\n",
    "def task1_1_partionByTime(table):\n",
    "    result = []\n",
    "    \n",
    "    for i in range(3):\n",
    "        result.append([])\n",
    "        \n",
    "\n",
    "    for eachRecord in table:\n",
    "        result[task1_1_whichProcessor(eachRecord[1])].append(eachRecord)\n",
    "    return result\n",
    "\n",
    "\n",
    "'''\n",
    "We alread get a partioned data. When user input a date value, firstly we use \"task1_1_whichProcessor\" to determine\n",
    "which worker has may have this value, then searh one by one in that worker. Everytime we find the value we put it to\n",
    "result list.\n",
    "'''\n",
    "\n",
    "def serialSearh(table, date):\n",
    "    for eachRecord in table:\n",
    "        if eachRecord[1] == date:\n",
    "            return eachRecord\n",
    "def task1_1_searching(date, partionedTable):\n",
    "    result = []\n",
    "    workerTask = []\n",
    "    pool = Pool(processes= 3)\n",
    "    \n",
    "    for i in partionedTable:\n",
    "        workerTask = pool.apply_async(serialSearh, args=(i,date))\n",
    "        output = workerTask.get()\n",
    "        result.append(output)\n",
    "    \n",
    "    pool.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = task1_1_partionByTime(climateData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " ['948702',\n",
       "  '2017-12-15',\n",
       "  '18',\n",
       "  '52',\n",
       "  '7.1',\n",
       "  '14',\n",
       "  '   74.5*',\n",
       "  '53.1',\n",
       "  ' 0.00I'],\n",
       " None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_1_searching('2017-12-15',task1_1_partionByTime(climateData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write an algorithm to find the latitude, longitude and confidence when the surface temperature (°C) was between 65 °C and 100 °C. Justify your choice of the data partition technique and search technique you have used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear search by range\n",
    "'''linear search: more flex in this time.\n",
    "Use binary search is inefficient (cause longer processing time) '''\n",
    "def linear_range_search(data, temperary_range):\n",
    "    result = []\n",
    "    found = None\n",
    "    for i in data:\n",
    "        temp = int(i[-1])\n",
    "        if (temp >= int(temperary_range[0])) and (temp <= int(temperary_range[1])):\n",
    "            result.append(i)\n",
    "    return result\n",
    "\n",
    "def index_calculate(data):\n",
    "    index = 0\n",
    "    if data > 100:\n",
    "        index = 10\n",
    "    elif data < 0:\n",
    "        index = 0\n",
    "    else:\n",
    "        index = data/10\n",
    "    return index   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_partitioning according to the temperature\n",
    "'''the surface temperature in fire data is not sorted therefore use range partitioning'''\n",
    "def Task1_2_searching(data, temperature_indices):\n",
    "    results = []\n",
    "    # range_partitioning\n",
    "    subsets = []\n",
    "    for i in range(11):\n",
    "        subsets.append([])         \n",
    "    for row in data[1:]:\n",
    "        index = int(index_calculate(int(row[-1])))\n",
    "        subsets[index].append(row)\n",
    "        \n",
    "    # parallel search\n",
    "    minIndex = int(index_calculate(temperature_indices[0]))\n",
    "    maxIndex = int(index_calculate(temperature_indices[1]))\n",
    "    newData = data[minIndex:(maxIndex+1)]\n",
    "    \n",
    "    pool = Pool(processes=3)\n",
    "    \n",
    "    for i in newData:\n",
    "        result = pool.apply(linear_range_search,[data, temperature_indices])\n",
    "        results.append(result)\n",
    "    pool.close()\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-37.966',\n",
       "  '145.051',\n",
       "  '341.8',\n",
       "  '2017-12-27T04:16:51',\n",
       "  '26.7',\n",
       "  '78',\n",
       "  '2017-12-27',\n",
       "  '68']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Task1_2_searching(fireData,[65,100])[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2：Parallel Join\n",
    "### 1. Write an algorithm to find surface temperature (°C), air temperature (°C), relative humidity and maximum wind speed. Justify your choice of the data partition technique and join technique you have used.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month(climate_date):\n",
    "    return int(climate_date[5:7])#month in ClimitData date \n",
    "'''range partition: \n",
    "    divide equally into [January to April],[May to August],[September to December] \n",
    "'''\n",
    "def range_partition(data, column):\n",
    "    result = [[],[],[]] \n",
    "    for i in data:\n",
    "        if month(i[column])<=4:#month smaller than Apr\n",
    "            result[0].append(i)\n",
    "        elif month(i[column])>8:\n",
    "            result[2].append(i)\n",
    "        else:\n",
    "            result[1].append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sort merge join:\n",
    "    sort the two tables (firedata climate data) based on the join attribute date\n",
    "    then merge these two tables. \n",
    "    Then do R and S comparsion. When the two date value match, palce the calue into query result.\n",
    "'''\n",
    "def sort_merge_join(data1,column_num1,attr1,data2, column_num2,attr2): \n",
    "    result = []\n",
    "    s_T1 = data1\n",
    "    s_T1 = sorted(s_T1, key=lambda s_T1: s_T1[column_num1]) #Climate data date col\n",
    "    s_T2 = data2\n",
    "    s_T2 = sorted(s_T2, key=lambda s_T2: s_T2[column_num2])#fire data date col\n",
    "    i = j = 0\n",
    "    while True:\n",
    "        r = s_T1[i][column_num1]\n",
    "        s = s_T2[j][column_num2]\n",
    "        if r < s: #date r< date s \n",
    "            i += 1\n",
    "        else:\n",
    "            if r > s:\n",
    "                j += 1\n",
    "            else:\n",
    "                record=[s_T1[i][column_num1]]\n",
    "                for x in attr1:\n",
    "                    record.append(s_T1[i][x])\n",
    "                for y in attr2:\n",
    "                    record.append(s_T2[j][y])\n",
    "                result.append(record)\n",
    "                j += 1\n",
    "\n",
    "        if (i == len(s_T1)) or (j == len(s_T2)):\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2_1(data1,column_num1,attr1,data2,column_num2,attr2):\n",
    "    results = []\n",
    "    pool = mp.Pool(processes=3)\n",
    "    T1_subsets = range_partition(data1, column_num1)\n",
    "    T2_subsets = range_partition(data2, column_num2)\n",
    "    for i in range(3):\n",
    "        #apply sort merge join\n",
    "        result = pool.apply(sort_merge_join, [T1_subsets[i],column_num1,attr1,T2_subsets[i], column_num2,attr2])\n",
    "        results.append(result)\n",
    "    \n",
    "    for i in results:\n",
    "        print(len(i))\n",
    "    return results\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1613\n",
      "781\n",
      "274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['2017-05-01', '14', '49.2', '10.5', '50'],\n",
       " ['2017-05-01', '14', '49.2', '10.5', '103'],\n",
       " ['2017-05-01', '14', '49.2', '10.5', '52'],\n",
       " ['2017-05-01', '14', '49.2', '10.5', '39'],\n",
       " ['2017-05-01', '14', '49.2', '10.5', '41']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Climate_attr = [2,3,4]#air temp, relatively humidy,windspeed\n",
    "Fire_attr = [7]#surface temp\n",
    "\n",
    "task2_1(climateData,1,Climate_attr,fireData,6,Fire_attr)[1][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write an algorithm to find datetime, air temperature (°C), surface temperature (°C) and confidence when the confidence is between 80 and 100. Justify your choice of the data partition technique and join technique you have used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For this task, I use date to partion data. \n",
    "The reason why I use date to partion is that using it can distribute task basically equally for each worker. \n",
    "'''\n",
    "def task2_2_whichProcessor(date):\n",
    "\n",
    "    if int(date[-2:]) <= 10:\n",
    "        return 0\n",
    "    else:\n",
    "        if int(date[-2:]) <= 20:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for this task, the date in each table is sorted by date, so I perfer to use sort-merge join.\n",
    "for each date both in firedata and climate. We can join them by using date easily.\n",
    "'''\n",
    "def task2_2_partionByTime(climateData, fireData):\n",
    "    result = []\n",
    "    fireData = sorted(fireData, key= lambda fireData:fireData[-2])\n",
    "    for i in range(3):\n",
    "        result.append([])\n",
    "        for j in range(2):\n",
    "            result[i].append([])\n",
    "        \n",
    "\n",
    "    for eachRecord in climateData:\n",
    "        result[task2_2_whichProcessor(eachRecord[1])][0].append(eachRecord)\n",
    "        \n",
    "    for eachRecord in fireData:\n",
    "        result[task2_2_whichProcessor(eachRecord[-2])][1].append(eachRecord)\n",
    "    \n",
    "    for eachworker in result:\n",
    "        for eachList in eachworker:\n",
    "            eachList.append([\"This\",\"is\",\"the\",\"end\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for each worker, they has two sorted table. One is part of firedata, other is part of climate.\n",
    "Using sort-merge in this task can decrease the caculate time.\n",
    "'''\n",
    "def task2InnerJoin(table):\n",
    "    result = []\n",
    "    fireList = list (table[1])\n",
    "    climateList = list(table[0])\n",
    "    climateIndex = fireIndex = 0\n",
    "    while True:\n",
    "        climateDate = climateList[climateIndex][1]\n",
    "        fireDate = fireList[fireIndex][-2]\n",
    "\n",
    "        if climateDate > fireDate:\n",
    "            fireIndex = fireIndex + 1\n",
    "        elif climateDate < fireDate:\n",
    "            climateIndex = climateIndex + 1\n",
    "        else:\n",
    "            if int(fireList[fireIndex][-3]) >= 80 and int(fireList[fireIndex][-3])<=100:\n",
    "                result.append({\",\".join([str(fireList[fireIndex][3]),str(fireList[fireIndex][5]),str(fireList[fireIndex][-1]),str(climateList[climateIndex][2])])})\n",
    "            if climateList[climateIndex][1] == fireList[fireIndex+1][-2]:\n",
    "                fireIndex += 1\n",
    "            else:\n",
    "                fireIndex += 1\n",
    "                climateIndex += 1\n",
    "        if (climateIndex >= len(climateList)-1) or (fireIndex >= len(fireList)-1):\n",
    "            break\n",
    "    return result\n",
    "\n",
    "def Task2_2(partionedTable):\n",
    "    result = []\n",
    "    local_result = []\n",
    "    workerTask = []\n",
    "    pool = Pool(processes= 3)\n",
    "    \n",
    "    for i in partionedTable:\n",
    "        workerTask = pool.apply_async(task2InnerJoin, [i])\n",
    "        output = workerTask.get()\n",
    "        for eachJoining in output:\n",
    "            result.append(eachJoining)\n",
    "    pool.close()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'2017-03-12T04:33:50,94,105,21'},\n",
       " {'2017-03-12T04:29:50,84,71,21'},\n",
       " {'2017-03-12T04:28:20,100,99,21'},\n",
       " {'2017-03-12T04:28:00,80,68,21'},\n",
       " {'2017-03-12T04:27:20,85,98,21'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task2InnerJoin(task2_2_partionByTime(climateData, fireData)[1])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1133"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Task2_2(task2_2_partionByTime(climateData, fireData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Sort\n",
    "### 1.Write an algorithm to sort fire data based on surface temperature (°C) in a ascending order. Justify your choice of the data partition technique and sorting technique you have used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In this task, the main point is surface temperature. So we can not use date to partion. Otherwhise the unmber of task \n",
    "for each worker is very unbalance. In other hand, we do not know too much about the value of surface temperature. As \n",
    "result, using round-robin is go way to dual with these data.\n",
    "'''\n",
    "def task3DataPartion(fireData):\n",
    "    result = []\n",
    "    for i in range(3):\n",
    "        result.append([])\n",
    "    \n",
    "    for index, eachRecord in enumerate(fireData):\n",
    "        index_bin = int(index%3)\n",
    "        result[index_bin].append(eachRecord)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "quick sort is a very effective method to sort data\n",
    "'''\n",
    "def quicksort(table):\n",
    "    if len(table) <= 1:\n",
    "        return table\n",
    "    less = []\n",
    "    greater = []\n",
    "    baseRecord = table.pop()\n",
    "    base = baseRecord[2]\n",
    "    for x in table:\n",
    "        if x[2] < base:\n",
    "            less.append(x)\n",
    "        else:\n",
    "            greater.append(x)\n",
    "    return quicksort(less) + [baseRecord] + quicksort(greater)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Bucause we assume that we have three worker, so we using 3-way merge. each way of a result made by each worker.\n",
    "'''\n",
    "def findMin(table):\n",
    "    minIndex = 0\n",
    "    minNum = float(table[0][2])\n",
    "    for index in range(len(table)):\n",
    "        if float(table[index][2]) < minNum:\n",
    "            minNum = float(table[index][2])\n",
    "            minIndex = index\n",
    "    return minIndex\n",
    "\n",
    "def ThreeWay(SortdePartionedTable):\n",
    "    indexes = []\n",
    "    result = []\n",
    "    T = []\n",
    "    ifMax = ['max','max','1000000000']\n",
    "    for i in range(len(SortdePartionedTable)):\n",
    "        indexes.append(0)\n",
    "    \n",
    "    while(True):\n",
    "        T = []\n",
    "        for i in range(len(SortdePartionedTable)):\n",
    "            \n",
    "            if (indexes[i]>= len(SortdePartionedTable[i])):\n",
    "                T.append(ifMax)\n",
    "            else:\n",
    "                T.append(SortdePartionedTable[i][indexes[i]])\n",
    "        #print(T)\n",
    "        \n",
    "        smallest = findMin(T)\n",
    "        smallestRecord = T[smallest]\n",
    "    \n",
    "        if(T[smallest] == ifMax):\n",
    "            break\n",
    "        \n",
    "        result.append(smallestRecord)\n",
    "        indexes[smallest] += 1\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paralleSort(partionedTable):\n",
    "    result = []\n",
    "    pool = Pool(processes=3)\n",
    "    \n",
    "    for eachList in partionedTable:\n",
    "        workTask = pool.apply_async(quicksort, [eachList])\n",
    "        result.append(workTask.get())\n",
    "    pool.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['-37.886',\n",
       "  '147.207',\n",
       "  '302',\n",
       "  '2017-07-02T04:28:42',\n",
       "  '10.7',\n",
       "  '50',\n",
       "  '2017-07-02',\n",
       "  '28']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThreeWay(paralleSort(task3DataPartion(fireData)))[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Parallel Group-By\n",
    "### 1. Write an algorithm to get the number of fire in each day. You are required to only display total number of fire and the date in the output. Justify your choice of the data partition technique if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Round-Robin is for balance task for each worker. then do inner group by. get each result of worker, put them to a dic\n",
    "the key of dic is the date, the value represent the how many fire in that day.\n",
    "'''\n",
    "def task4DataPartion(table):\n",
    "    result = []\n",
    "    #asumme that we have 3 workers\n",
    "    for i in range(3):\n",
    "        result.append([])\n",
    "    #for the balance work of each processor, I choose round roll bin partion\n",
    "    for index, eachrecord in enumerate(table):\n",
    "        index_bin = index%3\n",
    "        result[index_bin].append(eachrecord)   \n",
    "    return result\n",
    "\n",
    "def innerGroupBy(table):\n",
    "    dic = {}\n",
    "    for eachRecord in table:\n",
    "        key = eachRecord[-2]\n",
    "        if key not in dic:\n",
    "            dic[key] = 1\n",
    "        else:\n",
    "            dic[key] += 1\n",
    "    return dic\n",
    "\n",
    "def parallelMergeGroupBy(table):\n",
    "    result = {}\n",
    "    pool = Pool(processes=3)\n",
    "    \n",
    "    local_result_list = []\n",
    "    for i in table:\n",
    "        local_result = pool.apply_async(innerGroupBy, [i])\n",
    "        output = local_result.get()\n",
    "        local_result_list.append(output)\n",
    "    pool.close()\n",
    "\n",
    "    for dic in local_result_list:\n",
    "        for eachDate in dic:\n",
    "            if eachDate not in result:\n",
    "                result[eachDate] = dic.get(eachDate)\n",
    "            else:\n",
    "                result[eachDate] += dic.get(eachDate)  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2017-12-27': 4,\n",
       " '2017-12-21': 1,\n",
       " '2017-12-16': 15,\n",
       " '2017-12-15': 4,\n",
       " '2017-12-13': 1,\n",
       " '2017-12-10': 2,\n",
       " '2017-12-09': 4,\n",
       " '2017-12-08': 5,\n",
       " '2017-11-30': 31,\n",
       " '2017-11-29': 8,\n",
       " '2017-11-23': 5,\n",
       " '2017-11-21': 1,\n",
       " '2017-11-14': 3,\n",
       " '2017-11-13': 5,\n",
       " '2017-11-12': 5,\n",
       " '2017-11-11': 4,\n",
       " '2017-11-09': 10,\n",
       " '2017-11-05': 4,\n",
       " '2017-10-27': 5,\n",
       " '2017-10-26': 5,\n",
       " '2017-10-23': 1,\n",
       " '2017-10-21': 4,\n",
       " '2017-10-20': 3,\n",
       " '2017-10-18': 6,\n",
       " '2017-10-17': 5,\n",
       " '2017-10-15': 3,\n",
       " '2017-10-10': 3,\n",
       " '2017-10-08': 1,\n",
       " '2017-10-06': 2,\n",
       " '2017-10-04': 5,\n",
       " '2017-10-03': 18,\n",
       " '2017-10-02': 7,\n",
       " '2017-10-01': 8,\n",
       " '2017-09-29': 2,\n",
       " '2017-09-27': 7,\n",
       " '2017-09-26': 1,\n",
       " '2017-09-24': 28,\n",
       " '2017-09-23': 23,\n",
       " '2017-09-21': 2,\n",
       " '2017-09-20': 5,\n",
       " '2017-09-10': 4,\n",
       " '2017-08-14': 5,\n",
       " '2017-08-13': 9,\n",
       " '2017-08-10': 1,\n",
       " '2017-08-02': 2,\n",
       " '2017-07-31': 2,\n",
       " '2017-07-29': 2,\n",
       " '2017-07-06': 3,\n",
       " '2017-07-05': 1,\n",
       " '2017-07-02': 8,\n",
       " '2017-07-01': 4,\n",
       " '2017-06-30': 6,\n",
       " '2017-06-20': 6,\n",
       " '2017-06-18': 2,\n",
       " '2017-06-16': 2,\n",
       " '2017-06-14': 4,\n",
       " '2017-06-11': 2,\n",
       " '2017-06-09': 3,\n",
       " '2017-06-07': 14,\n",
       " '2017-06-04': 9,\n",
       " '2017-06-02': 11,\n",
       " '2017-06-01': 2,\n",
       " '2017-05-26': 4,\n",
       " '2017-05-24': 3,\n",
       " '2017-05-23': 5,\n",
       " '2017-05-22': 33,\n",
       " '2017-05-18': 7,\n",
       " '2017-05-16': 3,\n",
       " '2017-05-15': 102,\n",
       " '2017-05-14': 1,\n",
       " '2017-05-13': 54,\n",
       " '2017-05-12': 10,\n",
       " '2017-05-11': 19,\n",
       " '2017-05-10': 114,\n",
       " '2017-05-09': 13,\n",
       " '2017-05-08': 24,\n",
       " '2017-05-07': 3,\n",
       " '2017-05-06': 17,\n",
       " '2017-05-05': 31,\n",
       " '2017-05-04': 135,\n",
       " '2017-05-03': 64,\n",
       " '2017-05-02': 10,\n",
       " '2017-05-01': 20,\n",
       " '2017-04-29': 3,\n",
       " '2017-04-25': 3,\n",
       " '2017-04-24': 8,\n",
       " '2017-04-23': 19,\n",
       " '2017-04-22': 2,\n",
       " '2017-04-20': 31,\n",
       " '2017-04-19': 50,\n",
       " '2017-04-18': 325,\n",
       " '2017-04-17': 38,\n",
       " '2017-04-16': 18,\n",
       " '2017-04-15': 69,\n",
       " '2017-04-14': 18,\n",
       " '2017-04-13': 357,\n",
       " '2017-04-12': 69,\n",
       " '2017-04-11': 24,\n",
       " '2017-04-08': 20,\n",
       " '2017-04-07': 39,\n",
       " '2017-04-06': 118,\n",
       " '2017-04-05': 49,\n",
       " '2017-04-04': 89,\n",
       " '2017-04-03': 72,\n",
       " '2017-04-02': 5,\n",
       " '2017-04-01': 7,\n",
       " '2017-03-31': 22,\n",
       " '2017-03-29': 1,\n",
       " '2017-03-28': 54,\n",
       " '2017-03-26': 17,\n",
       " '2017-03-25': 13,\n",
       " '2017-03-19': 21,\n",
       " '2017-03-18': 3,\n",
       " '2017-03-17': 6,\n",
       " '2017-03-15': 7,\n",
       " '2017-03-14': 10,\n",
       " '2017-03-13': 2,\n",
       " '2017-03-12': 5,\n",
       " '2017-03-10': 8,\n",
       " '2017-03-09': 3,\n",
       " '2017-03-08': 2,\n",
       " '2017-03-06': 2,\n",
       " '2017-12-25': 1,\n",
       " '2017-12-12': 1,\n",
       " '2017-11-28': 1,\n",
       " '2017-11-22': 2,\n",
       " '2017-11-08': 2,\n",
       " '2017-10-28': 1,\n",
       " '2017-10-16': 1,\n",
       " '2017-10-07': 1,\n",
       " '2017-09-22': 1,\n",
       " '2017-08-05': 1,\n",
       " '2017-08-01': 2,\n",
       " '2017-07-14': 2,\n",
       " '2017-07-04': 1,\n",
       " '2017-06-03': 2,\n",
       " '2017-03-24': 2,\n",
       " '2017-03-07': 1,\n",
       " '2017-12-24': 1,\n",
       " '2017-12-14': 1,\n",
       " '2017-10-09': 1,\n",
       " '2017-06-22': 1,\n",
       " '2017-06-13': 1,\n",
       " '2017-05-17': 1,\n",
       " '2017-04-26': 1}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallelMergeGroupBy(task4DataPartion(fireData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668\n"
     ]
    }
   ],
   "source": [
    "A = parallelMergeGroupBy(task4DataPartion(fireData))\n",
    "x = 0\n",
    "for i in A:\n",
    "    x += A.get(i)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Write an algorithm to find the average surface temperature (°C) for each day. You are required to only display average surface temperature (°C) ​and the date in the output. Justify your choice of the data partition technique if any.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Round-Robin: simply and equally divide each record into each processor'''\n",
    "def task4DataPartion2(data):\n",
    "    result = []\n",
    "    for i in range(3):\n",
    "        result.append([])\n",
    "    \n",
    "    for index, element in enumerate(data): \n",
    "        index_bin = index%3\n",
    "        result[index_bin].append(element)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task4_groupby(dataset, date, surface):\n",
    "    dict = {}\n",
    "    for index, record in enumerate(dataset):\n",
    "        key = record[date]\n",
    "        val = int(record[surface])\n",
    "        if key not in dict:\n",
    "            dict[key] = [0,0]\n",
    "        dict[key][0] += val\n",
    "        dict[key][1] += 1\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''merge_all_groupby has two phases: a local aggregation step and global aggregation step\n",
    "-local groupby: groups local records according to date attribute and performs the aggregation function.\n",
    "-global groupby: final aggregation in each processor\n",
    "Finally \n",
    "-Calculate average temperature'''\n",
    "def task4_parallel_merge_all_groupby(dataset):\n",
    "    subsets = task4DataPartion2(dataset)\n",
    "    pool = mp.Pool(processes = 3)\n",
    "\n",
    "    # Local aggregation step\n",
    "    local_result = []\n",
    "    for s in subsets:\n",
    "        local_result.append(pool.apply(task4_groupby, [s, 6, 7])) \n",
    "    pool.close()\n",
    "\n",
    "    # Global aggregation step\n",
    "    result = {}\n",
    "    for r in local_result:\n",
    "        for key, val in r.items():\n",
    "            if key not in result:\n",
    "                result[key]= [0,0]\n",
    "            result[key][0] += val[0]\n",
    "            result[key][1] += val[1]\n",
    "            \n",
    "    #Average temperate\n",
    "    average = {} \n",
    "    for key, val in result.items():\n",
    "         average[key] = round(float(val[0]/val[1]),2)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2017-12-27': 62.75,\n",
       " '2017-12-21': 46.0,\n",
       " '2017-12-16': 57.8,\n",
       " '2017-12-15': 39.0,\n",
       " '2017-12-13': 60.0,\n",
       " '2017-12-10': 46.0,\n",
       " '2017-12-09': 58.25,\n",
       " '2017-12-08': 50.6,\n",
       " '2017-11-30': 52.42,\n",
       " '2017-11-29': 60.62,\n",
       " '2017-11-23': 58.8,\n",
       " '2017-11-21': 59.0,\n",
       " '2017-11-14': 52.0,\n",
       " '2017-11-13': 47.0,\n",
       " '2017-11-12': 53.0,\n",
       " '2017-11-11': 46.25,\n",
       " '2017-11-09': 61.3,\n",
       " '2017-11-05': 58.5,\n",
       " '2017-10-27': 50.4,\n",
       " '2017-10-26': 44.6,\n",
       " '2017-10-23': 38.0,\n",
       " '2017-10-21': 51.25,\n",
       " '2017-10-20': 50.0,\n",
       " '2017-10-18': 52.17,\n",
       " '2017-10-17': 51.6,\n",
       " '2017-10-15': 72.67,\n",
       " '2017-10-10': 53.33,\n",
       " '2017-10-08': 41.0,\n",
       " '2017-10-06': 44.0,\n",
       " '2017-10-04': 49.0,\n",
       " '2017-10-03': 50.0,\n",
       " '2017-10-02': 43.57,\n",
       " '2017-10-01': 48.25,\n",
       " '2017-09-29': 43.0,\n",
       " '2017-09-27': 49.71,\n",
       " '2017-09-26': 33.0,\n",
       " '2017-09-24': 53.57,\n",
       " '2017-09-23': 52.74,\n",
       " '2017-09-21': 40.5,\n",
       " '2017-09-20': 63.6,\n",
       " '2017-09-10': 56.5,\n",
       " '2017-08-14': 40.8,\n",
       " '2017-08-13': 49.0,\n",
       " '2017-08-10': 63.0,\n",
       " '2017-08-02': 63.5,\n",
       " '2017-07-31': 47.0,\n",
       " '2017-07-29': 48.0,\n",
       " '2017-07-06': 56.0,\n",
       " '2017-07-05': 45.0,\n",
       " '2017-07-02': 43.5,\n",
       " '2017-07-01': 30.5,\n",
       " '2017-06-30': 44.33,\n",
       " '2017-06-20': 71.17,\n",
       " '2017-06-18': 42.0,\n",
       " '2017-06-16': 42.5,\n",
       " '2017-06-14': 53.25,\n",
       " '2017-06-11': 41.5,\n",
       " '2017-06-09': 49.0,\n",
       " '2017-06-07': 51.86,\n",
       " '2017-06-04': 52.22,\n",
       " '2017-06-02': 47.73,\n",
       " '2017-06-01': 54.0,\n",
       " '2017-05-26': 49.5,\n",
       " '2017-05-24': 40.33,\n",
       " '2017-05-23': 51.2,\n",
       " '2017-05-22': 54.48,\n",
       " '2017-05-18': 44.14,\n",
       " '2017-05-16': 39.67,\n",
       " '2017-05-15': 53.95,\n",
       " '2017-05-14': 49.0,\n",
       " '2017-05-13': 58.61,\n",
       " '2017-05-12': 51.5,\n",
       " '2017-05-11': 59.37,\n",
       " '2017-05-10': 52.87,\n",
       " '2017-05-09': 42.46,\n",
       " '2017-05-08': 56.29,\n",
       " '2017-05-07': 50.33,\n",
       " '2017-05-06': 57.53,\n",
       " '2017-05-05': 51.71,\n",
       " '2017-05-04': 56.81,\n",
       " '2017-05-03': 56.8,\n",
       " '2017-05-02': 55.6,\n",
       " '2017-05-01': 68.4,\n",
       " '2017-04-29': 63.0,\n",
       " '2017-04-25': 48.67,\n",
       " '2017-04-24': 59.38,\n",
       " '2017-04-23': 53.89,\n",
       " '2017-04-22': 54.5,\n",
       " '2017-04-20': 56.58,\n",
       " '2017-04-19': 54.16,\n",
       " '2017-04-18': 53.37,\n",
       " '2017-04-17': 50.92,\n",
       " '2017-04-16': 48.72,\n",
       " '2017-04-15': 59.58,\n",
       " '2017-04-14': 61.94,\n",
       " '2017-04-13': 58.58,\n",
       " '2017-04-12': 52.7,\n",
       " '2017-04-11': 46.29,\n",
       " '2017-04-08': 60.75,\n",
       " '2017-04-07': 50.69,\n",
       " '2017-04-06': 61.71,\n",
       " '2017-04-05': 53.14,\n",
       " '2017-04-04': 62.57,\n",
       " '2017-04-03': 58.44,\n",
       " '2017-04-02': 45.2,\n",
       " '2017-04-01': 46.71,\n",
       " '2017-03-31': 48.73,\n",
       " '2017-03-29': 51.0,\n",
       " '2017-03-28': 60.93,\n",
       " '2017-03-26': 56.88,\n",
       " '2017-03-25': 66.0,\n",
       " '2017-03-19': 65.57,\n",
       " '2017-03-18': 79.33,\n",
       " '2017-03-17': 59.5,\n",
       " '2017-03-15': 46.0,\n",
       " '2017-03-14': 65.6,\n",
       " '2017-03-13': 38.5,\n",
       " '2017-03-12': 88.2,\n",
       " '2017-03-10': 69.38,\n",
       " '2017-03-09': 46.67,\n",
       " '2017-03-08': 51.5,\n",
       " '2017-03-06': 60.5,\n",
       " '2017-12-25': 54.0,\n",
       " '2017-12-12': 44.0,\n",
       " '2017-11-28': 42.0,\n",
       " '2017-11-22': 61.5,\n",
       " '2017-11-08': 45.5,\n",
       " '2017-10-28': 56.0,\n",
       " '2017-10-16': 36.0,\n",
       " '2017-10-07': 42.0,\n",
       " '2017-09-22': 45.0,\n",
       " '2017-08-05': 40.0,\n",
       " '2017-08-01': 58.0,\n",
       " '2017-07-14': 41.5,\n",
       " '2017-07-04': 40.0,\n",
       " '2017-06-03': 47.0,\n",
       " '2017-03-24': 49.0,\n",
       " '2017-03-07': 64.0,\n",
       " '2017-12-24': 32.0,\n",
       " '2017-12-14': 70.0,\n",
       " '2017-10-09': 44.0,\n",
       " '2017-06-22': 46.0,\n",
       " '2017-06-13': 41.0,\n",
       " '2017-05-17': 52.0,\n",
       " '2017-04-26': 34.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4_parallel_merge_all_groupby(fireData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "Write an algorithm to find the  average surface temperature   (°C)  for each weather station.You are required to only display  average surface temperature (°C)   and  the station  in the output.Justify your choice of the data partition and join technique.\n",
    "Hint: You need to join using the date and group by based on station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In order to distribute task balancely, and the data join by using date. So I choose the hash partion. Assume that we \n",
    "have 3 workers. For each worker, I distribute 1/3 of data. And for this task, task is based on date. So I also use the \n",
    "sort-merge to join them. After Join, only get the surface tempreture. Get the totoal number of tempreture, then divid \n",
    "the number of join result. Put them to a dic, which is the final result.\n",
    "'''\n",
    "def task5whichProcessor(date):\n",
    "\n",
    "    if int(date[-2:]) <= 10:\n",
    "        return 0\n",
    "    else:\n",
    "        if int(date[-2:]) <= 20:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "def task5_partionByTime(climateData, fireData):\n",
    "    result = []\n",
    "    fireData = sorted(fireData, key= lambda fireData:fireData[-2])\n",
    "    for i in range(3):\n",
    "        result.append([])\n",
    "        for j in range(2):\n",
    "            result[i].append([])\n",
    "        \n",
    "\n",
    "    for eachRecord in climateData:\n",
    "        result[task5whichProcessor(eachRecord[1])][0].append(eachRecord)\n",
    "        \n",
    "    for eachRecord in fireData:\n",
    "        result[task5whichProcessor(eachRecord[-2])][1].append(eachRecord)\n",
    "    \n",
    "    for eachworker in result:\n",
    "        for eachList in eachworker:\n",
    "            eachList.append([\"This\",\"is\",\"the\",\"end\"])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task5InnerProcess(table):\n",
    "    result = {}\n",
    "    fireList = list (table[1])\n",
    "    climateList = list(table[0])\n",
    "    climateIndex = fireIndex = 0\n",
    "    while True:\n",
    "        climateDate = climateList[climateIndex][1]\n",
    "        fireDate = fireList[fireIndex][-2]\n",
    "\n",
    "        if climateDate > fireDate:\n",
    "            fireIndex = fireIndex + 1\n",
    "        elif climateDate < fireDate:\n",
    "            climateIndex = climateIndex + 1\n",
    "        else:\n",
    "            key = climateList[climateIndex][0]\n",
    "            if key in result:\n",
    "                result[key][0] += float(fireList[fireIndex][-1])\n",
    "                result[key][1] += 1\n",
    "            else:\n",
    "                result[key] = [float(fireList[fireIndex][-1]),1]\n",
    "                \n",
    "            if climateList[climateIndex][1] == fireList[fireIndex+1][-2]:\n",
    "                fireIndex += 1\n",
    "            else:\n",
    "                fireIndex += 1\n",
    "                climateIndex += 1\n",
    "        if (climateIndex >= len(climateList)-1) or (fireIndex >= len(fireList)-1):\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task5ParallelProcess(table):\n",
    "    result = {}\n",
    "    finalResult = {}\n",
    "    pool = Pool(processes=3)\n",
    "    \n",
    "    for i in table:\n",
    "        localResult = pool.apply_async(task5InnerProcess, [i])\n",
    "        localOutput = localResult.get()\n",
    "        for x in localOutput:\n",
    "            if x in result:\n",
    "                result[x][0] += localOutput[x][0]\n",
    "                result[x][1] += localOutput[x][1]\n",
    "            else:\n",
    "                result[x] = localOutput[x]\n",
    "    pool.close()\n",
    "    for eachResult in result:\n",
    "        finalResult[eachResult] = (result[eachResult][0]/result[eachResult][1])\n",
    "    \n",
    "    return finalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'948701': 56.06938603868797, '948702': 52.148275862068964}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task5ParallelProcess(task5_partionByTime(climateData, fireData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
